{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chenweioh/GCP-Inspector-Toolkit/blob/main/MassLynx_Export_Data_Inspection_Toolkit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MassLynx Export Data Inspection Toolkit - User Manual\n",
        "\n",
        "---\n",
        "\n",
        "## Introduction:\n",
        "This toolkit allows users to easily inspect and analyze data exported from MassLynx 4.2. With a few steps, users can upload their data, visualize the internal standard, check time gaps between each injection, and identify any instances of manual integration flags.\n",
        "\n",
        "## Prerequisites:\n",
        "- Ensure you have the necessary data files exported from MassLynx 4.2 in a `.txt` format.\n",
        "- It is recommended to use Google Chrome for the best user experience, as I develope this tool in Colab using Chrome.\n",
        "\n",
        "## Step-by-step Guide:\n",
        "\n",
        "### 1. Data Upload:\n",
        "Begin by uploading the data files you wish to inspect. The toolkit will automatically process `.txt` files, reading the data before the \"Compound 2:\" line.\n",
        "\n",
        "### 2. Visualizing Internal Standard:\n",
        "Once the data is uploaded:\n",
        "- The toolkit will generate scatter plots for each unique type in the 'Type' column against the 'IS Area'.\n",
        "- The plots will be saved and bundled into a single Word document for you.\n",
        "\n",
        "### 3. Time Gap Inspection:\n",
        "This feature examines the time gaps between each injection:\n",
        "- The average time gap for each file is calculated.\n",
        "- Any gaps exceeding 20% of the average are highlighted and detailed in a comprehensive report.\n",
        "\n",
        "### 4. Manual Integration Flag Check:\n",
        "To ensure data integrity:\n",
        "- You will be prompted to enter a keyword for manual integration (default keyword is 'mm').\n",
        "- The toolkit then inspects each cell in the data for instances of the keyword. If found, the filename and row name will be recorded.\n",
        "  \n",
        "## File Outputs:\n",
        "- Internal Standard Plots: `plots.docx`\n",
        "- Time Gap Analysis Report: `time_gap_analysis.docx`\n",
        "- Manual Integration Review: `manual_integration_review.docx`\n",
        "\n",
        "**Note**: The aforementioned files will automatically download upon completion of their respective processes. They can typically be found in your browser's default download location or the \"Downloads\" folder.\n",
        "\n",
        "## Conclusion:\n",
        "The MassLynx Export Data Inspection Toolkit provides a streamlined and efficient approach to inspecting and reviewing your exported MassLynx 4.2 data. Ensure you regularly review this manual for any updates or additional features added to enhance your data analysis experience.\n",
        "\n",
        "Happy Analyzing!"
      ],
      "metadata": {
        "id": "TYTTHlOcoQDx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J9H9zhgS52Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbAYUuAtus-q",
        "outputId": "e793db6e-899d-4979-db88-31f66840205d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3e05d3ec-4650-4fa3-baab-22f26052be76\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3e05d3ec-4650-4fa3-baab-22f26052be76\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "def upload_and_load_txt():\n",
        "    uploaded = files.upload()\n",
        "    list_of_dataframes = []\n",
        "    filenames = []\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        # Read the file line by line and stop before \"Compound 2:\"\n",
        "        lines = []\n",
        "        try:\n",
        "            with open(filename, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    if \"Compound 2:\" in line:\n",
        "                        break\n",
        "                    lines.append(line)\n",
        "        except UnicodeDecodeError:\n",
        "            with open(filename, 'r', encoding='latin1') as f:\n",
        "                for line in f:\n",
        "                    if \"Compound 2:\" in line:\n",
        "                        break\n",
        "                    lines.append(line)\n",
        "\n",
        "        # Convert the list of lines back to a single string\n",
        "        data_str = '\\n'.join(lines)\n",
        "\n",
        "        # Now you can use pandas to convert this string to DataFrame\n",
        "        separator = \"\\t\"  # Change to \",\" or other as needed\n",
        "        header_row = 5  # Adjust as needed\n",
        "\n",
        "        try:\n",
        "            from io import StringIO\n",
        "            df = pd.read_csv(StringIO(data_str), sep=separator, header=header_row)\n",
        "            print(f\"Data from {filename}:\")\n",
        "            print(df.head())  # Debug: print the first few rows\n",
        "            list_of_dataframes.append(df)\n",
        "            filenames.append(filename)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file: {filename}. Error: {e}\")\n",
        "\n",
        "    return list_of_dataframes, filenames\n",
        "\n",
        "# Execute the function and store the list of DataFrames along with their filenames\n",
        "list_of_dataframes, filenames = upload_and_load_txt()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "SMp50UUnZ_i5",
        "outputId": "d7a8531e-b722-45c0-fdb7-0e9ccddd7637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Generating plot for 010822_S005&S006_01_00 (17).txt...\n",
            "Plot for 010822_S005&S006_01_00 (17).txt generated and added to the document.\n",
            "Generating plot for 010822_S007&S008_01_00 (11).txt...\n",
            "Plot for 010822_S007&S008_01_00 (11).txt generated and added to the document.\n",
            "Generating plot for 020822_S009&S010_01_00 (9).txt...\n",
            "Plot for 020822_S009&S010_01_00 (9).txt generated and added to the document.\n",
            "Generating plot for 020822_S011&S012_01_00 (3).txt...\n",
            "Plot for 020822_S011&S012_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 020822_S011&S012_01_01 (3).txt...\n",
            "Plot for 020822_S011&S012_01_01 (3).txt generated and added to the document.\n",
            "Generating plot for 030822_S013&S014_01_00 (3).txt...\n",
            "Plot for 030822_S013&S014_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 030822_S013&S014_01_01 (3).txt...\n",
            "Plot for 030822_S013&S014_01_01 (3).txt generated and added to the document.\n",
            "Generating plot for 030822_S015&S016_01_00 (3).txt...\n",
            "Plot for 030822_S015&S016_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 040822_S017&S018_01_00 (3).txt...\n",
            "Plot for 040822_S017&S018_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 050822_ISR01_01_00 (3).txt...\n",
            "Plot for 050822_ISR01_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 050822_S019&S020_01_00 (3).txt...\n",
            "Plot for 050822_S019&S020_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 060822_S021&S022_01_00 (3).txt...\n",
            "Plot for 060822_S021&S022_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 060822_S023&S024_01_00 (3).txt...\n",
            "Plot for 060822_S023&S024_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 070822_S025&S026_01_00 (8).txt...\n",
            "Plot for 070822_S025&S026_01_00 (8).txt generated and added to the document.\n",
            "Generating plot for 070822_S027&S028_01_00 (3).txt...\n",
            "Plot for 070822_S027&S028_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 080822_S029&S030_01_00 (3).txt...\n",
            "Plot for 080822_S029&S030_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 080822_S031&S032_01_00 (3).txt...\n",
            "Plot for 080822_S031&S032_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 090822_S033&S034_01_00 (3).txt...\n",
            "Plot for 090822_S033&S034_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 100822_ISR02_01_00 (3).txt...\n",
            "Plot for 100822_ISR02_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 100822_Repeats01_01_00 (3).txt...\n",
            "Plot for 100822_Repeats01_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 310722_S001&S002_01_00 (3).txt...\n",
            "Plot for 310722_S001&S002_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for 310722_S003&S004_01_00 (3).txt...\n",
            "Plot for 310722_S003&S004_01_00 (3).txt generated and added to the document.\n",
            "Generating plot for timegap_control_positive.txt...\n",
            "Plot for timegap_control_positive.txt generated and added to the document.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_0adf1901-1eec-4984-bde5-18a14eda0084\", \"plots.docx\", 694965)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Word document with plots has been downloaded. Check your 'Downloads' folder or the browser's default download location.\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from docx import Document\n",
        "import io\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import docx.shared\n",
        "\n",
        "def plot_and_save_graphs(dataframes, filenames):\n",
        "    # Create a new Word document\n",
        "    doc = Document()\n",
        "\n",
        "    for df, filename in zip(dataframes, filenames):\n",
        "        # Treat blank cells in 'IS Area' as 0 and convert 'IS Area' and 'Unnamed: 0' to numeric\n",
        "\n",
        "        df['IS Area'] = pd.to_numeric(df['IS Area'], errors='coerce')\n",
        "        df['IS Area'] = df['IS Area'].fillna(0)\n",
        "        df['Unnamed: 0'] = pd.to_numeric(df['Unnamed: 0'], errors='coerce')\n",
        "\n",
        "        # Indicate that the plot is being generated\n",
        "        print(f\"Generating plot for {filename}...\")\n",
        "\n",
        "        # Plotting the graph\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for t in df['Type'].unique():\n",
        "            subset = df[df['Type'] == t]\n",
        "            plt.scatter(subset['Unnamed: 0'], subset['IS Area'], label=t)\n",
        "\n",
        "        # Additional plot settings\n",
        "        plt.xlabel('Index')\n",
        "        plt.ylabel('IS Area')\n",
        "        plt.title(f'Plot from {filename}')\n",
        "        plt.legend()\n",
        "\n",
        "        # Save the plot to a BytesIO object\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "\n",
        "        # Add the plot to the Word document\n",
        "        doc.add_picture(buf, width=docx.shared.Inches(6))\n",
        "        plt.close()\n",
        "\n",
        "        # Indicate that the plot has been generated and added to the document\n",
        "        print(f\"Plot for {filename} generated and added to the document.\")\n",
        "\n",
        "    # Save the Word document to a BytesIO object\n",
        "    buf = io.BytesIO()\n",
        "    doc.save(buf)\n",
        "    buf.seek(0)\n",
        "\n",
        "    # Download the Word document with the graphs\n",
        "    with open(\"plots.docx\", \"wb\") as f:\n",
        "        f.write(buf.getvalue())\n",
        "    files.download(\"plots.docx\")\n",
        "\n",
        "    print(\"The Word document with plots has been downloaded. Check your 'Downloads' folder or the browser's default download location.\")\n",
        "\n",
        "# Assume list_of_dataframes and filenames are already defined\n",
        "plot_and_save_graphs(list_of_dataframes, filenames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VwRzzBqD5zr-",
        "outputId": "7ead5230-12b0-4028-b3a9-19fbf19c626f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_4e07b158-3212-44b4-b644-f200487e30fb\", \"time_gap_analysis.docx\", 37091)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from docx import Document\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# Function to process each dataframe\n",
        "def process_dataframe(df, filename, document):\n",
        "    # Convert the 'Acq.Time' column to datetime format\n",
        "    df['Acq.Time'] = pd.to_datetime(df['Acq.Time'], format='%H:%M:%S').dt.time\n",
        "\n",
        "    # Compute time gaps in seconds and add it to the dataframe\n",
        "    time_gap = [(datetime.combine(datetime.min, t) - datetime.combine(datetime.min, s)).seconds for s, t in zip(df['Acq.Time'], df['Acq.Time'][1:])]\n",
        "    time_gap = [0] + time_gap  # Add a zero for the first row\n",
        "    df['Time Gap'] = time_gap\n",
        "\n",
        "    # Compute the average time gap\n",
        "    avg_gap = sum(time_gap) / len(time_gap)\n",
        "\n",
        "    document.add_paragraph(f\"File: {filename}\")\n",
        "    document.add_paragraph(f\"Average Time Gap: {avg_gap:.2f} seconds\")\n",
        "\n",
        "    # Identify and print out the rows with time gaps exceeding 20% of average\n",
        "    excessive_gaps = []\n",
        "\n",
        "    for idx, gap in enumerate(time_gap):\n",
        "        if gap > 1.2 * avg_gap:\n",
        "            excessive_gaps.append(f\"Line {idx + 1} (Time: {df.iloc[idx]['Acq.Time']}): Time Gap of {gap} seconds is more than 20% above average. Corresponding row: {df.iloc[idx]['Name']}.\")\n",
        "\n",
        "    if excessive_gaps:\n",
        "        for message in excessive_gaps:\n",
        "            document.add_paragraph(message)\n",
        "    else:\n",
        "        document.add_paragraph(\"No time gaps more than 20% of average noted.\")\n",
        "    document.add_paragraph(\"\\n\")  # Add a space for clarity\n",
        "\n",
        "document = Document()\n",
        "document.add_heading('Subject Run review: Time Gap')\n",
        "\n",
        "for i, df in enumerate(list_of_dataframes):\n",
        "    process_dataframe(df, filenames[i], document)\n",
        "\n",
        "document.save('time_gap_analysis.docx')\n",
        "files.download('time_gap_analysis.docx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "TNIYQDIP-Ssm",
        "outputId": "3a087b26-c5c0-4354-978d-d6e281624464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the keyword for manual integration (default is 'mm'): mm\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_e8ea109b-b522-4bc9-8b37-1062036ddd5d\", \"manual_integration_review.docx\", 36911)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from docx import Document\n",
        "\n",
        "# Prompt the user for the keyword for manual integration, default to \"mm\"\n",
        "keyword = input(\"Enter the keyword for manual integration (default is 'mm'): \")\n",
        "if not keyword:\n",
        "    keyword = \"mm\"\n",
        "\n",
        "document = Document()\n",
        "document.add_heading('Manual Integration Review')\n",
        "document.add_paragraph(f\"Keyword searched for manual integration: '{keyword}'\")\n",
        "\n",
        "# Loop through each DataFrame and its corresponding filename\n",
        "for i, df in enumerate(list_of_dataframes):\n",
        "    filename = filenames[i]\n",
        "\n",
        "    # A flag to check if any instance of the keyword was found in the current DataFrame\n",
        "    found = False\n",
        "\n",
        "    # Check each cell in the DataFrame for the keyword\n",
        "    for idx, row in df.iterrows():\n",
        "        if keyword in row.astype(str).values:\n",
        "            # If found, set the flag to True and add a note to the document\n",
        "            found = True\n",
        "            document.add_paragraph(f\"In file {filename}, manual integration found at row with Name: {row['Name']}.\")\n",
        "\n",
        "    # If keyword was not found in the entire DataFrame, add a note to the document\n",
        "    if not found:\n",
        "        document.add_paragraph(f\"In file {filename}, no instances of manual integration were found.\")\n",
        "\n",
        "# Save the document\n",
        "document.save('manual_integration_review.docx')\n",
        "\n",
        "# Download the document\n",
        "from google.colab import files\n",
        "files.download('manual_integration_review.docx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44MVDjjxaGsk"
      },
      "outputs": [],
      "source": [
        "#Diagnostic tool\n",
        "for df in list_of_dataframes:\n",
        "    print(df.columns)\n",
        "for df in list_of_dataframes:\n",
        "    print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-78YFTNNhK7D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoA6p/U7xRFX8gbJizOjlM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}